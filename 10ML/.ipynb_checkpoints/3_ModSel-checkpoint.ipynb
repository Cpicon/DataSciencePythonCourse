{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 1. Ajuste de hiperparámetros: Métodos alternativos a fuerza bruta. \n",
    "\n",
    "Validación cruzada de métodos especificos.\n",
    "\n",
    "Algunos modelos pueden ajustar datos para un rango de parámetros casi tan eficientemente como para un parámetro. Esta característica tiene la ventaja de realizar una validación cruzada más eficiente para la selección de modelo para este parámetro. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio: \n",
    "\n",
    "Para los siguientes modelos de regresión obtenga los mejores parámetros y el score de MSE utilizando el dataset de \"boston house-prices\":\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear_model.LarsCV([fit_intercept, …]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear_model.LassoCV([eps, n_alphas, …]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear_model.LassoLarsCV([fit_intercept, …])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También para los siguientes métodos de clasificación, obtenga el mejor parámetro, los scores de precision-recall utilizando el dataset de \"boston house-prices\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear_model.RidgeCV([alphas, ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear_model.RidgeClassifierCV([alphas, …])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2. Criterios de información:\n",
    "\n",
    "Como ya vimos, algunos modelos pueden ofrecer información del óptimo parámetro de regulación basado en un criterio cerrado, computando un camino de regularización. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio: \n",
    "Obtenga las curvas de AIC y BIC para el siguiente modelo. Utilice el dataset de breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear_model.LassoLarsIC([criterion, …])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 1.3. Estimados Out of Bag:\n",
    "\n",
    "Es posible utilizar un ensamble de métodos para realizar bagging. Para esto se generan nuevos conjuntos de entrenamiento utilizando muestreo con remplazo, parte de los conjuntos de entrenamiento permanecen sin ser utilizados. Para cada clasificador, una diferente parte del conjunto de entrenamiento se deja \"fuera de la bolsa\".\n",
    "\n",
    "Esta porción que es dejada por fuera puede ser utilizada para estimar el error de generalización sin tener que depender de un conjunto de validación separado. Este estimado no requiere datos nuevos y puede ser utilizado para selección de modelo. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 RandomForestClassifier:\n",
    "\n",
    "ensemble.RandomForestClassifier([…]) \t\n",
    "\n",
    "Un RandomForest es un meta estimador que ajusta un número de clasificadores de árboles de decisión en diferentes submuestras del conjunto de datos y los utiliza los promedios para mejorar la precisión predictiva y el control del sobreajuste. El tamaño del subconjunto siempre es del tamaño de la muestra original, pero las muestras son dibujadas con remplazo si bootstrap=True."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 RandomForestRegressor:\n",
    "\n",
    "ensemble.RandomForestRegressor([…]) \t\n",
    "\n",
    "El regresor de random forest es un meta estimador que ajusta un número de árboles de decisión de clasificación en varios subconjuntos del dataset y utiliza promedios para mejorar la precisión predictiva y el control del sobreajuste. El tamaño del subconjunto de la muestra es del tamaño de la entrada original pero las muestras son dibujadas con remplazo si \"bootstrap=True.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1.3.3 GradientBoostingClassifier:\n",
    "\n",
    "ensemble.GradientBoostingClassifier([loss, …]) \t\n",
    "Este método construye un modelo aditivo; permite la optimización de funciones de pérdida arbitrarias. En cada etapa se ajustan \"n_classes_\" de regresión en el gradiente de la función de pérdida binomial o multinomial. La clasificación binaria es un casoespecial en el que sólo se induce un árbol de regresión. Las características son siempre permutadas en cada split. Por lo tanto, el mejor split puede variar, incluso en el mismo conjunto de entrenamiento y \"max_features=n_features\", si la mejora del criterio es idéntica para muchos splits enumerados durante la búsqueda del mejor split. Para obtener un comportamiento determinístico, se puede fijar el random_state.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.4 GradientBoostingRegressor\n",
    "\n",
    "\n",
    "ensemble.GradientBoostingRegressor([loss, …]) \t\n",
    "\n",
    "Crea un modelo aditivo por etapas; permite la optimización de funciones diferenciables arbitrarias. En cada etapa de regresión el arbol es ajustado al gradiente negativo de la función de costo. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Métricas de clasificación y regresión:\n",
    "Para el dataset iris, descarte una clase y obtenga las siguientes métricas y comparelas. Puede utilizar un SVC y recuerde que para obtener \"y_prob\" debe pedirle al constructor del objeto que le retorne las probabilidades asociadas a cada clase. De igual manera para los ejercicios de regresión (aquí utilice house prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#brier_score_loss(y_true, y_prob)\n",
    "#matthews_corrcoef(y_true, y_pred)  \n",
    "#log_loss(y_true, y_prob)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean_squared_error\n",
    "#r2_score\n",
    "#mean_squared_log_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Calibración de modelos de clasificación:\n",
    "\n",
    "Cuando se realiza clasificación usualmente se desea no sólo predecir la etiqueta de la clase sino la probabilidad asociada. Esta probabilidad da algún tipo de confianza sobre la predicción. Sin embargo, no todos los clasificadores proveen probabilidades calibradas, algunos son \"sobre confiados\" \\textit{overconfident} mientras que otros son \"sub confiados\" \\textit{underconfident}. Entonces, una calibración separada de probabilidades es usualmente deseable como postprocesamiento. Hay diferentes métodos que se pueden utilizar para evaluar clasificación y evalúan la calidad de las probabilidades utilizando el score de Brier. \n",
    "\n",
    "A continuación se compara la probabilidad utilizando un clasificador \"naive Bayes\" sin calibrar con una calibración signoidal, y con calibración no paramétrica isotónica. Uno puede observar que sólo el modelo no paramétrico es capaz de proveer una calibración que retorne las probabilidades cerca al 0.5 esperado para la mayoría de muestras que pertenecen al cluster de la mitad con etiquetas heterogéneas. Esto resulta en un muy mejorado puntaje de Brier.\n",
    "\n",
    "#### CalibratedClassifierCV\n",
    "\n",
    "Con esta clase, el estimador base es ajustado en el conjunto de entrenamiento del generador de cross-validation y el conjunto de prueba es utilizado para la calibración. Las probabilidades para cada uno de los folds son promediadas para predicción. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Curvas de validación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este ejemplo demuestra los problemas de subadaptación y sobreajuste y cómo podemos usar la regresión lineal con características polinómicas para aproximar funciones no lineales. La gráfica muestra la función que queremos aproximar, que es parte de la función coseno. Además, se muestran las muestras de la función real y las aproximaciones de diferentes modelos. Los modelos tienen características polinómicas de diferentes grados. Podemos ver que una función lineal (polinomio con grado 1) no es suficiente para ajustar las muestras de entrenamiento. Esto se llama underfitting. Un polinomio de grado 4 se aproxima a la función verdadera casi a la perfección. Sin embargo, para grados superiores, el modelo sobreajustará los datos de entrenamiento, es decir, aprenderá el ruido de los datos de entrenamiento. Evaluamos el sobreajuste / subadaptación cuantitativamente mediante validación cruzada. Calculamos el error cuadrático medio (MSE) en el conjunto de validación, cuanto más alto, menos probable es que el modelo se generalice correctamente a partir de los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
